# Pull Google Traffic Timeseries
# F31 Google Traffic COVID ITS Analysis
# Jenni A. Shearston 
# Updated 02/03/2022

####***********************
#### Table of Contents #### 
####***********************

# N: Notes
# 0: Preparation 
# 1: 


####**************
#### N: Notes ####
####**************

# Na Description
# In this script we 


####********************
#### 0: Preparation #### 
####********************

# 0a load packages
packages <- c("tidyverse", "raster", "rgdal", "terra", "sf", 'here', 'tictoc')
lapply(packages, library, character.only = TRUE)
rm(packages)

# 0b source our functions
# 0b.i Get the names of all of the scripts that are just functions
myFunctions <- list.files(path = here::here('functions'))

# 0.bii Define function to run sources 
source_myFunction <- function(FunctionName){
  source(here::here('functions', FunctionName))
}

# 0b.iii Source all the function scripts
# we don't actually need the assignment, it just removes annoying 
# output generated by the sourcing code. 
# since we are just sourcing these, we can just use map. 
a <- map(myFunctions, source_myFunction)
rm(a, myFunctions)

####*******************************************
#### 1: Prepare NYC Census Tract Shapefile #### 
####*******************************************

# 1a bring in nyc census
tracts_nyc <- st_read(here::here("data", "nyc_census_tracts",
                                 "nycgeo_census_tracts.shp"))

# 1b identify poly_id_var for function
#    Notes: This is the variable that uniquely identifies each polygon 
poly_id_var <- 'geoid'

# 1c assign polygon shapefile to polygons_of_interest function input
polygons_of_interest <- tracts_nyc


####*******************************************
#### 2: Prepare Polygon and Raster Inputs #### 
####*******************************************

# No need to edit anything in this section (Section 2). 
# This code needs to be run before the get_gt_agg_timeseries function 
# that loops through every Google Traffic image (gt_image_cat) 
# to put all key variables and datasets in the Global Environment 

# 2a Rename the poly_id and remove non-essential variables 
polygons_of_interest <- polygons_of_interest %>% 
  dplyr::rename(poly_id = !!poly_id_var) %>% 
  dplyr::select(poly_id)

# 2b make poly_id numeric
polygons_of_interest <- polygons_of_interest %>% 
  dplyr::mutate(poly_id = as.numeric(poly_id))

# 2c read in gt_geo_projected
gt_geo_projected <- raster::raster(here::here("data", "gt_geo_projected.tif"))

# 2d extract the extent (min and max lat and long) of gt_geo_projected 
#    Note: we use gt_geo_projected's extent because we worked to get it right in QGIS
gt_extent <- raster::extent(gt_geo_projected)

# 2e read the gt_image_cat.png as a matrix
# the actual datetime of this image is arbitrary
gt_matrix_cat <- png::readPNG(here::here('data', 'CCC_01_01_18__02_00.png'))

# 2f convert gt_matrix_unprojected to raster
gt_raster_unprojected <- raster::raster(gt_matrix_cat) 

# 2g change the extent of gt_raster_unprojected to reflect the extent of the gt_extent 
#    Note: now we are converting it to lat long 
#          here we georeference gt_raster_unprojected based on the location of gt_geo_projected
#          which was georeferenced in QGIS with 4 points
raster::extent(gt_raster_unprojected) <- c(gt_extent[1], gt_extent[2], gt_extent[3], gt_extent[4])

# 2h convert polygons_of_interest CRS to WGS84 
#    Note: this is important because gt_raster_projected has a CRS of WGS84 which 
#          uses lat/long and not decimal degrees or feet 
#          because gt_raster_unprojected has been assigned the extent of 
#          gt_raster_projected, which is in lat/long, the polygons_of_interest
#          file must have a CRS in lat/long in order for the rasterize
#          command to clip the shapefile to the gt_raster_unprojected's extent
polygons_of_interest_wgs84 <- sf::st_transform(polygons_of_interest, "WGS84")

# 2i convert polygons_of_interest to a raster with the dimensions and 
#    resolution of gt_raster_unprojected (~ 30s to 2min)
#    Note: The resulting raster will only have cells within the area defined by the 
#          overlap of gt_raster_unprojected and the polygons of interest 
#          The raster will have one column - the id of the polygon the cell belongs to
poly_gt_crosswalk <- raster::rasterize(polygons_of_interest_wgs84, gt_raster_unprojected, field = "poly_id")

# 2j convert to matrix
poly_matrix <- raster::as.matrix(poly_gt_crosswalk)

# 2k remove no longer needed files and run garbage collection to 
#    return memory 
#    Note: This is critical to conserve memory
rm(poly_gt_crosswalk, polygons_of_interest_wgs84, 
   gt_raster_unprojected, gt_extent, gt_geo_projected,
   gt_matrix_cat)
gc()


####********************************************************
#### 3: Prepare function inputs to create GT timeseries #### 
####********************************************************

# 3a create vectors of captured_datetimes of interest
# 3a.i March 9 to 13
march9to13 <- make_captured_datetime_vector(
  base_date = '2020/03/09 00:30',
  end_date = '2020/03/13 21:30')
# 3a.ii March 23 to 27
march23to27 <- make_captured_datetime_vector(
  base_date = '2020/03/23 00:30',
  end_date = '2020/03/27 21:30')
# 3a.iii Jan 1 to March 31
jantomar <- make_captured_datetime_vector(
  base_date = '2020/01/01 00:30',
  end_date = '2020/03/31 21:30')

# 3b reformat vectors of captured_datetimes of interest
# 3b.i March 9 to 13
march9to13 <- reformat_captured_datetime_vector(
  captured_datetime_vector = march9to13, 
  gt_dir = '/Users/jennishearston/Dropbox/CLEAN/2020/')
# 3b.ii March 23 to 27
march23to27 <- reformat_captured_datetime_vector(
  captured_datetime_vector = march23to27, 
  gt_dir = '/Users/jennishearston/Dropbox/CLEAN/2020/')
# 3b.iii Jan 1 to March 31
jantomar <- reformat_captured_datetime_vector(
  captured_datetime_vector = jantomar, 
  gt_dir = '/Users/jennishearston/Dropbox/CLEAN/2020/')


####*****************************************
#### 4: Create Google Traffic timeseries #### 
####*****************************************

# 4a pull pre-intervention work week for seminar presentation
#    Note: selected March 9-13 because the week directly before
#          NY on PAUSE was enacted had some pre-intervention traffic
#          decreases
#          ~4.8  minutes
tictoc::tic('completes 5 days of NYC tracts')
gt_timeseries <- get_gt_agg_timeseries(captured_datetime_vector_filename = march9to13, 
                                       dir_output = 'data', 
                                       name_output = 'google_traffic_march9to13')
tictoc::toc()

# 4b pull during-intervention work week for seminar presentation
#    Note: selected March 23-27 (March 22 is when NY on PAUSE begins)
#          if memory is exceeded in this second pull, clear the environment
#          and restart the R session, then rerun all the above code except for 4a
#          R holds the used memory and restarting the session seems to clear it
#          ~3.7 min
tictoc::tic('completes 5 days of NYC tracts')
gt_timeseries <- get_gt_agg_timeseries(captured_datetime_vector_filename = march23to27, 
                                       dir_output = 'data', 
                                       name_output = 'google_traffic_mar23to27')
tictoc::toc()

# 4c pull pre-intervention work week for seminar presentation
#    Note: ~ xx min
tictoc::tic('completes 3 months of NYC tracts')
gt_timeseries <- get_gt_agg_timeseries(captured_datetime_vector_filename = jantomar, 
                                       dir_output = 'data', 
                                       name_output = 'google_traffic_jantomar2020')
tictoc::toc()

# 4d read in timeseries to confirm they are correct
check_pre <- fst::read_fst(here::here('data', 'google_traffic_march9to13.fst'))
check_during <- fst::read_fst(here::here('data', 'google_traffic_march23to27.fst'))
check_3mon <- fst::read_fst(here::here('data', 'google_traffic_jantomar2020.fst'))

# 4e Create list of of datetimes with missing traffic data

# 4f Create list of census tract ids with traffic data


