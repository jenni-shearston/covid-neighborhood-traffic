# Pull Google Traffic Timeseries
# F31 Google Traffic COVID ITS Analysis
# Jenni A. Shearston 
# Updated 06/16/2023

####***********************
#### Table of Contents #### 
####***********************

# N: Notes
# 0: Preparation 
# 1: Set Function Inputs
# 2: Prepare Polygon and Raster Inputs
# 3: Prepare Vectors of captured_datetimes of Interest
# 4: Create Google Traffic Timeseries: Polygons
# 5: Confirm Aggregation Through Stats and Mapping

####**************
#### N: Notes ####
####**************

# Na Description
# In this script we convert Google Traffic images (rasters) into a csv of
# traffic congestion colors aggregated to census tracts. 

####********************
#### 0: Preparation #### 
####********************

# 0a Specify needed packages
packages <- c('tidyverse', 'raster', 'rgdal', 'terra', 'sf', 'here', 'doParallel',
              'tictoc', 'png', 'fst', 'lubridate', 'stringr', 'parallel', 'foreach',
              'viridis')

# 0b Load or install and load all packages
lapply(packages, FUN = function(x){
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)}
})
rm(packages)

# 0c Source our functions
# 0c.i Get the names of all of the scripts that are functions
myFunctions <- list.files(path = here::here('functions'))

# 0c.ii Define function to run sources 
source_myFunction <- function(FunctionName){
  source(here::here('functions', FunctionName))
}

# 0c.iii Source all the function scripts
#        Note: We don't actually need the assignment, it just 
#              removes annoying output generated by the sourcing code. 
#              Since we are just sourcing these, we can use map. 
a <- purrr::map(myFunctions, source_myFunction)
rm(a, myFunctions)

####*****************************
#### 1: Set Function Inputs #### 
####****************************

# 1a Set inputs for function that prepares polygon and raster files
polygons_of_interest_path = here::here('data', 'nyc_census_tracts', 'nycgeo_census_tracts.shp')
poly_id_var = 'geoid'
gt_geo_projected_path = here::here('data', 'needed_for_gt_to_polygons_function', 'gt_geo_projected.tif')
gt_image_cat_path = here::here('data', 'needed_for_gt_to_polygons_function', 'CCC_01_01_18__02_00.png')
poly_matrix_output_path = here::here('data', 'needed_for_gt_to_polygons_function', 'poly_matrix_nyc_2010CTs.rds')

# 1b Set inputs for functions that prepare vectors of datetimes of interest
#    Note: One of either end_date or sampling_quantity_units_direction should be set as 'none' 
#            (both should not have actual values)
#          captured_datetime_vector is already set; it is the name of the vector that holds
#            the output of the make_captured_datetime_vector function
base_date = '2020/01/01 00:00'
end_date = '2020/12/31 23:00'
sampling_quantity_units_direction = 'none'
timezone = 'America/New_York'
gt_dir = '/Users/jennishearston/Dropbox/JENNI_F31_DATA'

# 1c Set inputs for function that creates a timeseries of traffic data aggregated to polygon ids
#    Note: captured_datetime_vector_filename is already set; it is the name of the vector
#            that holds the output of the reformat_captured_datetime_vector function
#          gt_dir was set in section 1b above
#          poly_matrix is already set; it is the name of the matrix that holds the output of 
#            the create_polygon_matrix function
gt_agg_timeseries_output_path = here::here('data/processed_data', 'gt2020_2010CTs.fst')
method = 'parallel'

####*******************************************
#### 2: Prepare Polygon and Raster Inputs #### 
####*******************************************

# 2a Convert polygon shapefile to a matrix with the dimensions and resolution
#    of a traffic map image (create poly_matrix)
#    Note: Rather than using a spatial join to connect polygon ID information to 
#          traffic map image information, we convert both the polygon shapefile and
#          the traffic map image to matrices with the same dimensions and resolution,
#          such that matrix location (matrix index) contains the spatial information;
#          e.g., a point in index[1,2] is at the same spatial location in both the 
#          polygon and traffic matrices. This function saves poly_matrix as well.
tictoc::tic('creates poly_matrix for nyc tracts')
poly_matrix <- 
  create_polygon_matrix(polygons_of_interest_path = polygons_of_interest_path,
                        poly_id_var = poly_id_var,
                        gt_geo_projected_path = gt_geo_projected_path,
                        gt_image_cat_path = gt_image_cat_path,
                        poly_matrix_output_path = poly_matrix_output_path)
tictoc::toc()

####**********************************************************
#### 3: Prepare Vectors of captured_datetimes of Interest #### 
####**********************************************************

# 3a Create vector of captured_datetimes of interest
#    Note: The function will fill an NA for any datetimes between the base_date and 
#          end_date that gt_image_cats are not available for
captured_datetime_vector <- make_captured_datetime_vector(
  base_date = base_date,
  end_date = end_date,
  sampling_quantity_units_direction = sampling_quantity_units_direction,
  timezone = timezone)

# 3b Reformat vector of captured_datetimes of interest as gt_image_cat filenames
captured_datetime_vector_formatted <- reformat_captured_datetime_vector(
  captured_datetime_vector = captured_datetime_vector, 
  gt_dir = gt_dir)

####***************************************************
#### 4: Create Google Traffic Timeseries: Polygons #### 
####***************************************************

# 4a Run function to aggregate Google Traffic images to polygons
#    Note: It is highly recommended that you first run the function for one 
#          week of time, to get a sense of how long it will take to run
#          your full datetime vector. A year's worth of analysis for a small
#          city at hourly resolution may take ~ 10-15 hours.
tictoc::tic('completes 1 year of nyc tracts')
gt_timeseries <- 
  get_gt_agg_timeseries(captured_datetime_vector_filename = captured_datetime_vector_formatted, 
                        gt_agg_timeseries_output_path = gt_agg_timeseries_output_path,
                        gt_dir = gt_dir,
                        method = method,
                        poly_matrix = poly_matrix)
tictoc::toc()

####******************************************************
#### 5: Confirm Aggregation Through Stats and Mapping #### 
####******************************************************

# 5a Run summary statistics to review data
summary(gt_timeseries)

# 5b Map to confirm spatial area is correct
# 5b.i Load NYC census shapefile
nyc_geo <- st_read(polygons_of_interest_path)
# 5b.ii Merge geometry with timeseries
gt_timeseries <- gt_timeseries %>% 
  mutate(poly_id = as.character(poly_id)) %>% 
  left_join(nyc_geo, by = c('poly_id' = 'geoid'))
# 5b.iii Create chloropleth map
gt_timeseries %>% 
  filter(captured_datetime == '0101200000') %>% 
  mutate(roads = gt_pixcount_gray + gt_pixcount_red + gt_pixcount_orange + 
           gt_pixcount_green + gt_pixcount_maroon + gt_pixcount_construction +
           gt_pixcount_emergency) %>% 
  ggplot(aes(fill = gt_pixcount_green/roads, 
             geometry = geometry)) + 
  geom_sf() + # Adding 'colour = NA' will remove boundaries around each ct
  scale_fill_viridis("% Green Roads in CT") + 
  theme_void() 






